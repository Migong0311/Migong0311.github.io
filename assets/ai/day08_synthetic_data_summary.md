

# 🧩 **Day08 (실습-문제) 합성 데이터 실습 — 시험 대비 정리**

---

## 🎯 **학습 목표**

> 본 실습의 핵심은 **“AI가 스스로 데이터를 만들고 평가하는 자동화 루프(Auto Loop)”**를 구축하는 것입니다.

| 학습 요소              | 핵심 내용                      |
| ------------------ | -------------------------- |
| Synthetic Data     | 인공적으로 생성된 학습용 데이터의 개념과 필요성 |
| Prompt Engineering | 프롬프트 설계 기술 (명확성, 구조화, 맥락성) |
| LLM as a Judge     | LLM이 생성 결과를 자동 평가하는 시스템    |
| API + JSON         | 실시간 API 통신 및 구조적 데이터 처리 방식 |

---

## 1️⃣ **환경 설정 및 기초 라이브러리**

### 📦 **필수 라이브러리 개요**

| 라이브러리     | 역할                      | 비고                           |
| --------- | ----------------------- | ---------------------------- |
| `dotenv`  | `.env` 파일 기반 API Key 관리 | 보안상 코드에 Key 직접 노출 금지         |
| `httpx`   | 비동기(Async) HTTP 클라이언트   | `asyncio.gather()`로 병렬 처리 가능 |
| `json`    | 텍스트 응답을 Python dict로 변환 | `json.loads()` 사용            |
| `asyncio` | 비동기 처리 프레임워크            | LLM 호출 병렬화                   |

---

### ⚙️ **환경 변수 관리 핵심**

```python
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.getenv("UPSTAGE_API_KEY")
```

✅ **보안 포인트**

* `.env` 파일을 Git에 올리지 않기 (`.gitignore` 필수)
* 클라우드 노트북(Colab 등) 사용 시, `os.environ`으로 임시 등록 가능

---

### 💡 **비동기 통신(httpx)**

* `httpx.AsyncClient()`는 **동시에 여러 API 호출 가능**
* `await asyncio.gather()`로 병렬 요청 처리
* 대기시간 감소 → **응답속도 향상 + 비용 절감**

> 💡 시험 포인트:
> “비동기 방식(asyncio)의 장점은 무엇인가요?”
> → 병렬 처리로 **지연(latency)** 감소, **I/O 효율 향상**

---

### 🧠 **JSON 처리 기본기**

```python
import json
result = json.loads(response.text)
```

* 모델이 반환한 텍스트를 **딕셔너리 형태**로 파싱
* 형식 오류 시 `try/except`로 예외 처리
* `response_format` 또는 **명시적 JSON Schema**를 통해 출력 안정성 확보

> ✅ 팁: ChatGPT류 모델은 JSON 구조를 잘못 닫는 경우가 있으므로,
>
> ````python
> output = output_text[output_text.index("```json")+7 : output_text.index("```")]
> ````

---

## 2️⃣ **합성 데이터(Synthetic Data) 생성**

### 📘 **개념 요약**

> 실제 데이터가 아닌, **AI 모델이 인공적으로 생성한 데이터**를 의미.
> 품질 좋은 합성 데이터는 “데이터 확장”과 “프라이버시 보호”를 동시에 달성합니다.

| 활용 분야  | 예시                          |
| ------ | --------------------------- |
| 의료 데이터 | 환자 가상 데이터 생성 (Privacy 보완)   |
| 대화 AI  | Chatbot 학습용 문장 자동 생성        |
| 이미지 생성 | Stable Diffusion, DALL·E 활용 |
| 추천 시스템 | 사용자 행동 로그 합성                |

---

### 📈 **합성 데이터의 장점**

1. **데이터 부족 문제 해소**
2. **민감정보(PII) 노출 방지**
3. **다양한 시나리오 생성 가능 (Edge Case Simulation)**
4. **비용 절감 + 확장성 우수**

> ⚠️ 단점: 현실 데이터와의 **분포 차이(Distribution Shift)** 발생 가능

---

## 3️⃣ **Prompt Engineering 핵심 정리**

| 구성요소        | 설명        | 예시                         |
| ----------- | --------- | -------------------------- |
| Role        | 모델의 역할 지정 | “당신은 영화 평론가입니다.”           |
| Task        | 수행할 명령    | “공포 영화를 하나 추천하세요.”         |
| Constraints | 출력 형식/제한  | “JSON으로 응답하세요.”            |
| Examples    | 예시 출력 제공  | “예: {title, year, reason}” |

---

### 🧠 **좋은 프롬프트의 조건**

| 조건  | 설명                        |
| --- | ------------------------- |
| 명확성 | 모호한 단어 대신 구체적 지시          |
| 구조성 | JSON, Markdown 등 출력 포맷 고정 |
| 맥락성 | 역할·대상·목적 포함               |
| 일관성 | 동일 스타일 유지로 학습 효율 ↑        |

---

### 💬 **Generator Prompt 설계 예시**

```text
당신은 세상의 모든 영화를 꿰뚫고 있는 영화 전문가 ‘시네마스터’입니다.
사용자의 요청에 맞춰 영화를 추천합니다.
반드시 하나의 영화만, 다음 형식(JSON)으로 응답합니다.
```

```json
{
  "title": "영화 제목",
  "year": "개봉 연도",
  "reason": "추천 이유"
}
```

---

### 🌡️ **Temperature (창의성 조절)**

| 값    | 특징             | 사용 예시        |
| ---- | -------------- | ------------ |
| 0.0  | 일관성 높음 (정형 응답) | 규칙 기반 데이터 생성 |
| 0.7  | 중간             | 대화형 데이터      |
| 1.0↑ | 창의성·랜덤성↑       | 스토리·아이디어 생성용 |

> 📍시험 포인트:
> “Temperature가 높을수록 모델의 출력 다양성이 증가하지만, 일관성은 낮아진다.”

---

## 4️⃣ **LLM as a Judge (모델 스스로 평가하기)**

### ⚖️ **핵심 개념**

> “LLM이 자신이 만든 데이터를 다시 평가하여 품질을 측정하는 구조”

| 항목   | 설명                             |
| ---- | ------------------------------ |
| 목적   | 생성 품질 자동 평가                    |
| 장점   | 빠르고 일관된 평가 가능                  |
| 한계   | 동일 모델 사용 시 **긍정 편향(bias)**     |
| 권장사항 | 생성모델 ≠ 평가모델 (cross-evaluation) |

---

### 📋 **Judge System Prompt 구조 예시**

```text
당신의 역할은 모델 답변 자동 평가자입니다.
입력 프롬프트와 모델 답변을 보고, 기준(criteria)에 따라 평가하세요.
```

출력 형식(JSON):

```json
{
  "score": 1~5,
  "comment": "평가 근거 (한국어 1~3문장)"
}
```

---

### 🧾 **평가 기준 (예시)**

| 기준  | 설명                               |
| --- | -------------------------------- |
| 관련성 | 요청한 주제와 일치하는가?                   |
| 완전성 | 필수 항목(title, year, reason) 포함 여부 |
| 논리성 | 추천 이유가 타당한가?                     |
| 창의성 | 과도한 반복 없이 다양한 결과를 제시하는가?         |

> 💡 Tip: 채점은 1~5점 척도로 수행 (1=부적합, 5=탁월)

---

## 5️⃣ **전체 실습 흐름 요약**

| 단계           | 구성 요소              | 핵심 개념                      |
| ------------ | ------------------ | -------------------------- |
| **① 환경설정**   | dotenv, httpx      | API 보안 및 비동기 통신            |
| **② 데이터 생성** | Prompt Engineering | 합성 데이터 생성 (Generator)      |
| **③ 품질 평가**  | LLM as a Judge     | 자동 품질 점수화 (score, comment) |
| **④ 개선 루프**  | 평가 피드백 반영          | 지속적 품질 향상 (Auto Feedback)  |

---

## 6️⃣ **핵심 이론 & 시험 대비 요약**

| 개념                     | 정의                 | 시험 포인트                      |
| ---------------------- | ------------------ | --------------------------- |
| **Synthetic Data**     | AI가 생성한 인공 데이터     | 데이터 부족 해결책                  |
| **Prompt Engineering** | 출력 제어를 위한 입력 설계 기술 | Role + Task + Constraint 구조 |
| **LLM as a Judge**     | 생성 모델의 결과를 자동 평가   | 평가 모델은 별도 구성 필요             |
| **Temperature**        | 모델의 창의성 제어         | 다양성 ↔ 일관성 Trade-off         |
| **JSON 출력**            | 구조적 응답 포맷          | 후처리 및 파싱 용이성 확보             |

---

## 🧭 **최종 결론**

> 합성 데이터는 **데이터 중심 AI 개발의 새로운 패러다임**입니다.
> LLM은 단순한 생성기(generator)가 아니라,
> **“프롬프트 설계 → 데이터 생성 → 품질 평가 → 자동 개선”**의
> 전 과정을 스스로 수행하는 **Self-Evolving System**으로 진화하고 있습니다.

